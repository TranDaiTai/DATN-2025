{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52cdc4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giai ƒêo·∫°n 2 extract skill v√† Job t·ª´ description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d058c805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'windows server', 'exchange', 'french', 'networking'}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)  # Fix l·ªói t·ª´ tr∆∞·ªõc\n",
    "\n",
    "# Sample JD t·ª´ file c·ªßa b·∫°n\n",
    "sample_jd =\"\"\"\n",
    "We are looking for a supportive IT specialist to join our service desk team.\n",
    "You will be the first point of contact for users reporting incidents, handling inquiries via phone, email, or ticketing system.\n",
    "Responsibilities include diagnosing and resolving hardware/software issues quickly, escalating complex problems when needed,\n",
    "and ensuring high customer satisfaction.\n",
    "The ideal candidate has experience supporting Microsoft Windows environments, including Active Directory (AD), Exchange Server, and basic networking.\n",
    "You should be able to multitask effectively in a fast-paced setting, remain calm when dealing with frustrated users,\n",
    "and have excellent interpersonal skills to explain technical concepts clearly.\n",
    "Fluency in Englisch is required; French is a plus.\n",
    "Ability to adapt quickly to new tools and work well in a team-oriented environment is essential.\n",
    "\"\"\"\n",
    "# DB skill m·∫´u (t·ª´ O*NET/Lightcast + m·ªü r·ªông)\n",
    "skills_db = [\n",
    "    'python', 'sql', 'java', 'javascript', 'excel', 'project management', 'communication', 'troubleshooting', 'networking',\n",
    "    'Active Diractory', 'windows server', 'exchange', 'ticketing systems', 'english', 'french', 'information systems',\n",
    "    'information technology', 'help desk', 'it support', 'machine learning', 'data analysis', 'toeic', 'ielts',\n",
    "]\n",
    "\n",
    "# Tokenize JD (NLP)\n",
    "tokens = word_tokenize(sample_jd.lower())\n",
    "\n",
    "# Extract b·∫±ng similarity (NLP + rule)\n",
    "extracted_skills = []\n",
    "vectorizer = TfidfVectorizer(lowercase=True, ngram_range=(1,3))  # th√™m ngram ƒë·ªÉ b·∫Øt \"active directory\"\n",
    "vectorizer.fit(skills_db)  # CH·ªà fit tr√™n skills_db.3\n",
    "\n",
    "skills_vec = vectorizer.transform(skills_db)\n",
    "tokens_vec = vectorizer.transform([' '.join(tokens)])\n",
    "\n",
    "for i, skill in enumerate(skills_db):\n",
    "    sim = cosine_similarity(skills_vec[i], tokens_vec)[0][0]\n",
    "    if sim > 0.2 :  # Rule: threshold\n",
    "        extracted_skills.append(skill)\n",
    "\n",
    "# Output unique skills\n",
    "print(set(extracted_skills)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39be862",
   "metadata": {},
   "source": [
    "# T·∫°i sao b·ªè TF-IDF + Cosine Similarity trong b√†i to√°n tr√≠ch xu·∫•t Skill?\n",
    "\n",
    "Trong demo ban ƒë·∫ßu, ph∆∞∆°ng ph√°p sau ƒë∆∞·ª£c s·ª≠ d·ª•ng:\n",
    "\n",
    "- TF-IDF Vectorizer\n",
    "- Cosine Similarity\n",
    "\n",
    "Tuy nhi√™n, c√°ch ti·∫øp c·∫≠n n√†y **kh√¥ng ph√π h·ª£p cho b√†i to√°n tr√≠ch xu·∫•t skill t·ª´ Job Description (JD) trong th·ª±c t·∫ø**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùå V·∫•n ƒë·ªÅ v·ªõi TF-IDF + Cosine Similarity\n",
    "\n",
    "### 1Ô∏è‚É£ Similarity ƒë∆∞·ª£c t√≠nh tr√™n to√†n b·ªô JD\n",
    "\n",
    "- Job Description th∆∞·ªùng r·∫•t d√†i (v√†i trƒÉm t·ª´)\n",
    "- Skill th∆∞·ªùng r·∫•t ng·∫Øn (1‚Äì3 t·ª´)\n",
    "\n",
    "V√≠ d·ª•:\n",
    "\n",
    "- Skill: `active directory`\n",
    "- JD: c·∫£ m·ªôt ƒëo·∫°n m√¥ t·∫£ d√†i\n",
    "\n",
    "Khi t√≠nh cosine similarity gi·ªØa:\n",
    "- vector c·ªßa skill\n",
    "- vector c·ªßa to√†n b·ªô JD\n",
    "\n",
    "‚Üí Gi√° tr·ªã similarity th∆∞·ªùng ch·ªâ kho·∫£ng:\n",
    "0.2 ‚Äì 0.4\n",
    "\n",
    "‚û°Ô∏è R·∫•t kh√≥ ƒë·∫∑t threshold h·ª£p l√Ω ƒë·ªÉ quy·∫øt ƒë·ªãnh skill c√≥ xu·∫•t hi·ªán hay kh√¥ng.\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ D·ªÖ b·ªã nhi·ªÖu b·ªüi c√°c t·ª´ ph·ªï bi·∫øn\n",
    "\n",
    "C√°c t·ª´ xu·∫•t hi·ªán nhi·ªÅu trong JD nh∆∞:\n",
    "\n",
    "- experience\n",
    "- team\n",
    "- knowledge\n",
    "- responsible\n",
    "\n",
    "Nh·ªØng t·ª´ n√†y c√≥ tr·ªçng s·ªë TF-IDF cao v√† xu·∫•t hi·ªán d√†y ƒë·∫∑c ‚Üí **l√†m lo√£ng vector**.\n",
    "\n",
    "‚û°Ô∏è Skill quan tr·ªçng d·ªÖ b·ªã ‚Äúch√¨m‚Äù trong kh√¥ng gian vector.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Kh√¥ng x·ª≠ l√Ω t·ªët c√°c bi·∫øn th·ªÉ chu·ªói\n",
    "\n",
    "TF-IDF + cosine similarity **kh√¥ng linh ho·∫°t** v·ªõi c√°c tr∆∞·ªùng h·ª£p:\n",
    "\n",
    "| Tr∆∞·ªùng h·ª£p | K·∫øt qu·∫£ |\n",
    "|-----------|--------|\n",
    "| `Active Directory` vs `Directory Active` | Similarity th·∫•p |\n",
    "| Sai ch√≠nh t·∫£ (`Active Diractory`) | G·∫ßn nh∆∞ kh√¥ng match |\n",
    "| Vi·∫øt t·∫Øt (`AD`) | Kh√¥ng match |\n",
    "\n",
    "‚û°Ô∏è Ph∆∞∆°ng ph√°p n√†y kh√¥ng x·ª≠ l√Ω t·ªët:\n",
    "- Th·ª© t·ª± t·ª´\n",
    "- Sai ch√≠nh t·∫£ ( trong truong hop cua Active Directory)\n",
    "- Bi·∫øn th·ªÉ ng√¥n ng·ªØ ( do csdl skill con han che va khong ho tro variant )\n",
    "\n",
    "---\n",
    "\n",
    "### 4Ô∏è‚É£ Hi·ªáu nƒÉng k√©m khi danh s√°ch skill l·ªõn\n",
    "\n",
    "Khi `skills_db` c√≥ h√†ng ngh√¨n skill:\n",
    "\n",
    "- Ph·∫£i transform to√†n b·ªô JD\n",
    "- Ph·∫£i transform t·ª´ng skill\n",
    "- Ph·∫£i t√≠nh cosine similarity cho t·ª´ng c·∫∑p\n",
    "\n",
    "‚û°Ô∏è T·ªën th·ªùi gian v√† kh√¥ng ph√π h·ª£p cho h·ªá th·ªëng real-time.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Tiep can voi phuong phap Exact Match + Fuzzy Matching t·ªët h∆°n?\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Exact Match ‚Äì B·∫Øt ch√≠nh x√°c tuy·ªát ƒë·ªëi\n",
    "\n",
    "- N·∫øu skill xu·∫•t hi·ªán **nguy√™n vƒÉn** trong JD ‚Üí b·∫Øt ngay\n",
    "- Kh√¥ng c·∫ßn threshold\n",
    "- Kh√¥ng c√≥ false positive\n",
    "\n",
    "‚û°Ô∏è ƒê·ªô ch√≠nh x√°c g·∫ßn nh∆∞ 100%.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Fuzzy Matching ‚Äì X·ª≠ l√Ω bi·∫øn th·ªÉ c·ª±c t·ªët\n",
    "\n",
    "Fuzzy matching (RapidFuzz) cho ph√©p:\n",
    "\n",
    "- Sai ch√≠nh t·∫£:\n",
    "  - `Activ Directory` ‚Üí `Active Directory`\n",
    "- Th·ª© t·ª± t·ª´ kh√°c nhau:\n",
    "  - `Directory Active` ‚Üî `Active Directory`\n",
    "- K·∫øt h·ª£p synonym map:\n",
    "  - `AD` ‚Üí `Active Directory`\n",
    "\n",
    "‚û°Ô∏è Ph√π h·ª£p v·ªõi JD th·ª±c t·∫ø (d·ªØ li·ªáu b·∫©n).\n",
    "\n",
    "---\n",
    "Fuzzy Matching (RapidFuzz): Kh√¥ng d√πng vector, m√† d√πng string distance (Levenshtein/ratio tr√™n token sorted). Scan sliding window (n-gram) tr√™n JD ƒë·ªÉ so tr·ª±c ti·∫øp v·ªõi skill.\n",
    "Kh√°c bi·ªát: T·∫≠p trung v√†o similarity chu·ªói (b·ªè qua th·ª© t·ª±, b·∫Øt typo t·ªët nh∆∞ \"Diractory\" ‚Üí 94% match \"Directory\"). Nhanh, kh√¥ng c·∫ßn fit vector, nh∆∞ng thi·∫øu context (kh√¥ng b·∫Øt synonym tr·ª´ khi b·∫°n add variant v√†o DB).\n",
    "\n",
    "### üß† D·ªÖ ki·ªÉm so√°t v√† debug\n",
    "\n",
    "- Bi·∫øt r√µ:\n",
    "  - Skill n√†o ƒë∆∞·ª£c match\n",
    "  - Match b·∫±ng exact hay fuzzy\n",
    "  - ƒêi·ªÉm similarity bao nhi√™u\n",
    "\n",
    "‚û°Ô∏è D·ªÖ tinh ch·ªânh threshold v√† logic.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ ƒê·ªô ch√≠nh x√°c th·ª±c t·∫ø cao (90‚Äì95%)\n",
    "\n",
    "- ƒê√¢y l√† c√°ch m√† **ƒëa s·ªë h·ªá th·ªëng ATS th∆∞∆°ng m·∫°i** ƒëang s·ª≠ d·ª•ng\n",
    "- ƒê√£ ƒë∆∞·ª£c ki·ªÉm ch·ª©ng trong c√°c h·ªá th·ªëng tuy·ªÉn d·ª•ng th·ª±c t·∫ø\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ So s√°nh tr·ª±c ti·∫øp tr√™n JD m·∫´u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2688cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Active Diractory',\n",
       " 'english',\n",
       " 'exchange',\n",
       " 'french',\n",
       " 'networking',\n",
       " 'ticketing systems'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from rapidfuzz import fuzz, process\n",
    "from skillNer.general_params import SKILL_DB\n",
    "import re\n",
    "\n",
    "def normalize(text):\n",
    "    return re.sub(r'\\s+', ' ', text.strip().lower())\n",
    "\n",
    "def extract_skills(jd_text, skills_db, threshold=85):\n",
    "    jd_normalized = normalize(jd_text)\n",
    "    tokens = jd_normalized.split()\n",
    "    extracted = set()\n",
    "\n",
    "    for skill in skills_db:\n",
    "        skill_norm = normalize(skill)\n",
    "        skill_tokens = skill_norm.split()\n",
    "        k = len(skill_tokens)\n",
    "\n",
    "        for i in range(len(tokens) - k + 1):\n",
    "            window = \" \".join(tokens[i:i+k])\n",
    "            ratio = fuzz.ratio(skill_norm, window)\n",
    "\n",
    "            if ratio >= threshold:\n",
    "                extracted.add(skill)\n",
    "                break\n",
    "\n",
    "    return extracted\n",
    "\n",
    "extract_skills(sample_jd,skills_db) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203666c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66379385",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'JOB_DB' from 'skillNer.general_params' (c:\\Users\\trand\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skillNer\\general_params.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatcher\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PhraseMatcher\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskillNer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneral_params\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JOB_DB\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mskillNer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mskill_extractor_class\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SkillExtractor\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load model spaCy (ch·ªâ l√†m 1 l·∫ßn)\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'JOB_DB' from 'skillNer.general_params' (c:\\Users\\trand\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skillNer\\general_params.py)"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from skillNer.general_params import JOB_DB\n",
    "from skillNer.skill_extractor_class import SkillExtractor\n",
    "\n",
    "# Load model spaCy (ch·ªâ l√†m 1 l·∫ßn)\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Kh·ªüi t·∫°o SkillExtractor\n",
    "skill_extractor = SkillExtractor(nlp, JOB_DB, PhraseMatcher)\n",
    "\n",
    "# Tr√≠ch xu·∫•t\n",
    "annotations = skill_extractor.annotate(sample_jd)\n",
    "\n",
    "# In k·∫øt qu·∫£ s·∫°ch (kh√¥ng c·∫ßn import extract_skills n·ªØa)\n",
    "print(\"SkillNER extracted skills:\\n\")\n",
    "full_matches = annotations['results']['full_matches']\n",
    "ngram_scored = annotations['results']['ngram_scored']\n",
    "\n",
    "all_skills = full_matches +ngram_scored\n",
    "\n",
    "for item in all_skills:\n",
    "    skill_name = item['doc_node_value']\n",
    "    score = item['score']\n",
    "    skill_type = item.get('type', 'N/A')  # m·ªôt s·ªë c√≥ type nh∆∞ 'fullUni', 'lowForm'...\n",
    "    print(f\"- {skill_name} (score: {score:.2f}, type: {skill_type})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d3d0e8",
   "metadata": {},
   "source": [
    "# Trong b√†i to√°n tr√≠ch xu·∫•t skill t·ª´ Job Description (JD), c√≥ hai lo·∫°i skill:\n",
    "\n",
    "Explicit skills (skill ƒë∆∞·ª£c n√≥i tr·ª±c ti·∫øp, r√µ r√†ng)\n",
    "‚Üí D·ªÖ b·∫Øt b·∫±ng c√°c ph∆∞∆°ng ph√°p ƒë∆°n gi·∫£n.\n",
    "Implicit skills (skill ng·∫ßm hi·ªÉu, kh√¥ng ƒë∆∞·ª£c vi·∫øt tr·ª±c ti·∫øp)\n",
    "‚Üí R·∫•t kh√≥ b·∫Øt n·∫øu ch·ªâ d√πng exact/fuzzy matching ho·∫∑c rule-based.\n",
    "\n",
    "C√¢u ƒë√≥ mu·ªën n√≥i: C√°c ph∆∞∆°ng ph√°p ch√∫ng ta ƒëang th·∫£o lu·∫≠n (Exact Match, Fuzzy Matching v·ªõi RapidFuzz, SkillNER, TF-IDF) ƒë·ªÅu r·∫•t y·∫øu trong vi·ªác b·∫Øt implicit skills. N·∫øu b·∫°n th·ª±c s·ª± c·∫ßn b·∫Øt lo·∫°i n√†y th√¨ ph·∫£i d√πng c√°c m√¥ h√¨nh BERT-based NER fine-tuned.\n",
    "V√≠ d·ª• minh h·ªça r√µ nh·∫•t\n",
    "Gi·∫£ s·ª≠ JD c√≥ c√¢u:\n",
    "\"You will be the first point of contact for users reporting incidents, handling inquiries via phone, email, or ticketing system. Responsibilities include diagnosing and resolving hardware/software issues quickly, escalating complex problems when needed, and ensuring high customer satisfaction.\"\n",
    "Explicit skills (d·ªÖ b·∫Øt):\n",
    "\n",
    "ticketing system / ticketing systems\n",
    "hardware\n",
    "software\n",
    "\n",
    "‚Üí Exact/Fuzzy/SkillNER b·∫Øt ƒë∆∞·ª£c d·ªÖ d√†ng.\n",
    "Implicit skills (kh√≥ b·∫Øt):\n",
    "\n",
    "Help desk support ho·∫∑c IT support\n",
    "(v√¨ m√¥ t·∫£ ƒë√∫ng c√¥ng vi·ªác c·ªßa help desk, nh∆∞ng kh√¥ng vi·∫øt tr·ª±c ti·∫øp t·ª´ ‚Äúhelp desk‚Äù)\n",
    "Troubleshooting\n",
    "(c√¢u ‚Äúdiagnosing and resolving issues‚Äù ch√≠nh l√† ƒë·ªãnh nghƒ©a c·ªßa troubleshooting, nh∆∞ng kh√¥ng d√πng t·ª´ ƒë√≥)\n",
    "Customer service ho·∫∑c Customer support\n",
    "(‚Äúensuring high customer satisfaction‚Äù, ‚Äúremain calm with frustrated users‚Äù ‚Üí r√µ r√†ng c·∫ßn k·ªπ nƒÉng ph·ª•c v·ª• kh√°ch h√†ng)\n",
    "Incident management\n",
    "(‚Äúreporting incidents‚Äù, ‚Äúescalating complex problems‚Äù ‚Üí ƒë√∫ng quy tr√¨nh incident management trong ITIL)\n",
    "\n",
    "‚Üí C√°c ph∆∞∆°ng ph√°p Exact/Fuzzy/SkillNER kh√¥ng b·∫Øt ƒë∆∞·ª£c nh·ªØng skill n√†y v√¨:\n",
    "\n",
    "Ch√∫ng ch·ªâ t√¨m chu·ªói g·∫ßn gi·ªëng v·ªõi skill trong database.\n",
    "Kh√¥ng hi·ªÉu ng·ªØ nghƒ©a s√¢u, kh√¥ng suy lu·∫≠n ƒë∆∞·ª£c ‚Äúdiagnosing and resolving issues‚Äù = ‚Äútroubleshooting‚Äù."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff511e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service desk\n",
      "customer satisfaction\n",
      "microsoft window\n",
      "active directory\n",
      "team orient\n",
      "reporting incidents\n",
      "inquiries\n",
      "complex problems\n",
      "ad\n",
      "exchange server\n",
      "basic networking\n",
      "multitask\n",
      "french\n",
      "adapt\n",
      "exchange\n",
      "networking\n",
      "french\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# T·∫°o PhraseMatcher ri√™ng cho custom\n",
    "custom_matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")  # Case-insensitive\n",
    "patterns = list(nlp.pipe(skills_db))  # T·∫°o doc patterns\n",
    "custom_matcher.add(\"CUSTOM_SKILLS\", patterns)\n",
    "\n",
    "def extract_with_custom(text):\n",
    "    # Tr√≠ch xu·∫•t b·∫±ng SkillNER m·∫∑c ƒë·ªãnh\n",
    "    annotations = skill_extractor.annotate(text)\n",
    "    \n",
    "    # Th√™m custom matching\n",
    "    doc = nlp(text.lower())  # Ho·∫∑c text g·ªëc n·∫øu mu·ªën gi·ªØ case\n",
    "    custom_matches = custom_matcher(doc)\n",
    "    \n",
    "    custom_extracted = [doc[start:end].text for match_id, start, end in custom_matches]\n",
    "    \n",
    "    # Merge k·∫øt qu·∫£ (lo·∫°i duplicate)\n",
    "    default_skills = [item['doc_node_value'] for item in annotations['results']['full_matches'] + annotations['results']['ngram_scored']]\n",
    "    all_skills = default_skills +custom_extracted\n",
    "    \n",
    "    return all_skills\n",
    "\n",
    "# Test v·ªõi JD m·∫´u\n",
    "all_skills = extract_with_custom(sample_jd)\n",
    "for item in all_skills:\n",
    "    print( item ) \n",
    "\n",
    "# ‚Üí S·∫Ω b·∫Øt th√™m \"toeic\", \"devops\", \"kubernetes\" d√π kh√¥ng c√≥ trong SKILL_DB g·ªëc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
